import torch
import numpy as np
from torch import nn

from easyvolcap.engine import EVALUATORS
from easyvolcap.utils.console_utils import *
from easyvolcap.utils.base_utils import dotdict
from easyvolcap.utils.data_utils import Visualization
from easyvolcap.runners.visualizers.volumetric_video_visualizer import VolumetricVideoVisualizer


@EVALUATORS.register_module()
class VolumetricVideoEvaluator(VolumetricVideoVisualizer):
    def __init__(self,
                 skip_time_in_summary: int = 0,  # skip first 5 image in summary
                 ) -> None:
        super().__init__(verbose=False)
        self.skip_time_in_summary = skip_time_in_summary
        self.metrics = []

        from easyvolcap.utils.loss_utils import mse as compute_mse

        def psnr(x: torch.Tensor, y: torch.Tensor):
            mse = compute_mse(x, y).mean()
            psnr = (1 / mse.clip(1e-10)).log() * 10 / np.log(10)
            return psnr.item()  # tensor to scalar

        from skimage.metrics import structural_similarity as compare_ssim

        def ssim(xs: torch.Tensor, ys: torch.Tensor):
            return np.mean([compare_ssim(x.detach().cpu().numpy(), y.detach().cpu().numpy(), channel_axis=-1, data_range=2.0) for x, y in zip(xs, ys)])

        def lpips(x: torch.Tensor, y: torch.Tensor):
            # B, H, W, 3
            # B, H, W, 3
            if not hasattr(self, 'compute_lpips'):
                import lpips as lpips_module
                log('Initializing LPIPS network')
                self.compute_lpips = lpips_module.LPIPS(net='vgg', verbose=False).cuda()

            return self.compute_lpips(x.permute(0, 3, 1, 2) * 2 - 1, y.permute(0, 3, 1, 2) * 2 - 1).mean().item()

        self.compute_metrics = [psnr, ssim, lpips]

    def evaluate(self, output: dotdict, batch: dotdict):
        img, img_gt, _ = super().generate_type(output, batch, Visualization.RENDER)  # TODO: This is a bit wasteful since the images are already generated by the visualizer
        if img_gt is None: return dotdict()
        img, img_gt = img[..., :3], img_gt[..., :3]  # image loss are compute in 3 channels (last are only for saving)

        metrics = dotdict()
        for compute in self.compute_metrics:
            metrics[compute.__name__] = compute(img, img_gt)  # actual computation of the metrics
        self.metrics.append(metrics)

        # Read rendering time from output
        if 'time' in output.keys():
            metrics.time = output.time

        # For recording
        c = batch.meta.camera_index.item()
        f = batch.meta.frame_index.item()
        log(f'camera: {c}', f'frame: {f}', metrics)
        scalar_stats = dotdict({f'{k}_frame{f:04d}_cam{c:04d}': v for k, v in metrics.items()})

        return scalar_stats

    def summarize(self):
        summary = dotdict()
        if len(self.metrics):
            for key in self.metrics[0].keys():
                values = [m[key] for m in self.metrics]
                if key == 'time':
                    if np.sum(values) == 0: continue  # timer has not been enabled
                    values = values[self.skip_time_in_summary:]
                    summary[f'{key}{self.skip_time_in_summary:}+_mean'] = np.mean(values)
                    summary[f'{key}{self.skip_time_in_summary:}+_std'] = np.std(values)
                else:
                    summary[f'{key}_mean'] = np.mean(values)
                    summary[f'{key}_std'] = np.std(values)
        self.metrics.clear()  # clear mean after extracting summary
        if len(summary): log(summary)
        return summary


@EVALUATORS.register_module()
class NoopEvaluator(VolumetricVideoVisualizer):
    def __init__(self) -> None:
        pass
